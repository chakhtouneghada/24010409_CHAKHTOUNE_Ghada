# üè¶ Projet Data Science : Analyse de Transactions Bancaires

Ce d√©p√¥t illustre un projet complet de Data Science appliqu√© √† des donn√©es de transactions bancaires, en suivant la structure p√©dagogique du document ¬´ Correction-Projet ¬ª.

---

## 1. Contexte m√©tier

Dans le secteur bancaire, le volume de transactions et la diversit√© des canaux (ATM, agence, en ligne) rendent difficile la d√©tection manuelle des op√©rations √† risque.  
L‚Äôobjectif est de construire un pipeline de Machine Learning permettant d‚Äôexplorer les transactions et de simuler une d√©tection de transactions potentiellement frauduleuses.

---

## 2. Donn√©es utilis√©es

- **Fichier principal :** `bank_transactions_data.csv`  
- **Granularit√© :** 1 ligne = 1 transaction  
- **Types de variables (exemples) :**
  - Identifiants : `TransactionID`, `AccountID`
  - Financi√®res : `TransactionAmount`, `AccountBalance`
  - Temporelles : `TransactionDate`, `PreviousTransactionDate`
  - Comportement : `Channel`, `Location`, `DeviceID`, `LoginAttempts`, `TransactionDuration`
  - D√©mographiques : `CustomerAge`, `CustomerOccupation`

Une cible binaire simul√©e `is_risky` est construite √† partir du montant de la transaction (transactions tr√®s √©lev√©es marqu√©es comme ¬´ √† risque ¬ª).  
Dans un cas r√©el, cette cible serait fournie par l‚Äôhistorique des fraudes connues.

---

## 3. Pipeline Data Science

Le code principal se trouve dans un script (ou notebook) inspir√© de `PROJET_DS.ipynb` et suit les √©tapes suivantes :

1. **Importation des biblioth√®ques**  
   NumPy, Pandas, Matplotlib, Seaborn, scikit-learn (RandomForestClassifier, train_test_split, m√©triques).

2. **Chargement des donn√©es**  
   - Lecture de `bank_transactions_data.csv` avec Pandas.  
   - Affichage de la taille du dataset et de la liste des colonnes.

3. **Construction de la cible `is_risky` (exemple p√©dagogique)**  
   - Transactions dont le montant est sup√©rieur au 95e centile marqu√©es comme `1`.  
   - Les autres transactions marqu√©es comme `0`.

4. **Pr√©paration des features**  
   - Suppression des colonnes purement identifiantes (`TransactionID`, `AccountID`, dates, IP).  
   - Encodage one-hot des variables cat√©gorielles.  
   - S√©paration en `X` (features) et `y` (cible).

5. **Nettoyage et imputation**  
   - Utilisation de `SimpleImputer(strategy="mean")` pour remplacer les valeurs manquantes des colonnes num√©riques.  
   - Cr√©ation d‚Äôune matrice propre `X_clean`.

6. **Analyse exploratoire (EDA)**  
   - Statistiques descriptives sur les montants et soldes.  
   - Histogramme de la distribution de `TransactionAmount`.  
   - Possibilit√© d‚Äôajouter une heatmap de corr√©lation sur un sous-ensemble de variables.

7. **Split Train / Test**  
   - `train_test_split` avec `test_size=0.2`, `random_state=42`, `stratify=y`.  
   - Objectif : √©valuer la capacit√© de g√©n√©ralisation du mod√®le.

8. **Mod√©lisation : Random Forest**  
   - Utilisation de `RandomForestClassifier(n_estimators=100, class_weight="balanced")`.  
   - Entra√Ænement sur le jeu d‚Äôentra√Ænement uniquement.

9. **√âvaluation**  
   - Calcul de l‚Äôaccuracy.  
   - Rapport de classification (precision, recall, f1-score).  
   - Matrice de confusion visualis√©e via Seaborn.

---

## 4. R√©sultats et interpr√©tation

- Le mod√®le permet d‚Äôidentifier une partie des transactions marqu√©es comme `is_risky` sur le jeu de test.  
- L‚Äôaccuracy est compl√©t√©e par l‚Äôanalyse de la **precision** et du **recall** sur la classe `1` (transactions √† risque).  
- Dans un contexte bancaire r√©el, la priorit√© serait de maximiser le recall de la fraude tout en contr√¥lant le nombre de faux positifs.

---

## 5. Limites et pistes d‚Äôam√©lioration

- La cible `is_risky` est ici simul√©e √† partir d‚Äôun simple seuil de montant, ce qui ne refl√®te pas toute la complexit√© de la fraude r√©elle.  
- Le mod√®le pourrait √™tre am√©lior√© par :
  - L‚Äôing√©nierie de features (fr√©quence des transactions par client, temps depuis la derni√®re transaction, agr√©gations par canal, etc.).  
  - L‚Äôutilisation de m√©thodes d√©di√©es aux donn√©es d√©s√©quilibr√©es (SMOTE, ajustement de seuils de d√©cision, etc.).  
  - La mise en place d‚Äôune validation crois√©e plus rigoureuse.

---

## 6. Utilisation

1. Cloner le d√©p√¥t.  
2. Placer `bank_transactions_data.csv` √† la racine du projet.  
3. Ex√©cuter le script Python principal ou ouvrir le notebook correspondant.  
4. Consulter les sorties (m√©triques, graphiques) pour analyser les performances du mod√®le.

---

## 7. R√©f√©rences

Ce projet suit la logique p√©dagogique du document ¬´ Correction-Projet : Anatomie d‚Äôun projet Data Science ¬ª (contexte m√©tier, data wrangling, EDA, split, mod√©lisation, √©valuation).
